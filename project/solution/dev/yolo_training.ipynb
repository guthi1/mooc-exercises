{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guthi1/mooc-exercises/blob/daffy-project/project/solution/dev/yolo_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mIJd6b6pbsk"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E2APl4pnbAa"
      },
      "source": [
        "import os\n",
        "import contextlib\n",
        "@contextlib.contextmanager\n",
        "def directory(name):\n",
        "  ret = os.getcwd()\n",
        "  os.chdir(name)\n",
        "  yield None\n",
        "  os.chdir(ret)\n",
        "\n",
        "import subprocess\n",
        "def run(input, exception_on_failure=False):\n",
        "  try:\n",
        "    program_output = subprocess.check_output(f\"{input}\", shell=True, universal_newlines=True, stderr=subprocess.STDOUT)\n",
        "  except Exception as e:\n",
        "    if exception_on_failure:\n",
        "      raise e\n",
        "    program_output = e.output\n",
        "\n",
        "    return program_output\n",
        "\n",
        "def runp(input, exception_on_failure=False):\n",
        "    print(input)\n",
        "    print(run(input, exception_on_failure))\n",
        "\n",
        "#make boxes to xywh format:\n",
        "def xminyminxmaxymax2xywfnormalized(box, image_size):\n",
        "    xmin, ymin, xmax, ymax = np.array(box, dtype=np.float64)\n",
        "    center_x = (xmin+xmax)/2\n",
        "    center_y = (ymin+ymax)/2\n",
        "    width = xmax-xmin\n",
        "    height = ymax-ymin\n",
        "\n",
        "    normalized = np.array([center_x, center_y, width, height])/image_size\n",
        "    return np.round(normalized, 5)\n",
        "\n",
        "def train_test_split(filenames, split_percentage, dataset_dir):\n",
        "    train_txt = np.array(filenames)\n",
        "    np.random.shuffle(train_txt)\n",
        "    nb_things = len(train_txt)\n",
        "    sp = int(split_percentage * nb_things)\n",
        "    train_txt, val_txt = train_txt[:sp], train_txt[sp:]\n",
        "\n",
        "    print(\"ALL IMAGE NAMES TO MOVE DURING THIS SPLIT:\", filenames)\n",
        "    print(\"DATASET DIRECTORY\", dataset_dir)\n",
        "\n",
        "    def mv(img_name, to_train):\n",
        "        print(\"MOVING IMG NAMED\", img_name)\n",
        "\n",
        "        dest = \"train\" if to_train else \"val\"\n",
        "        runp(f\"mv {dataset_dir}/images/{img_name}.jpg {dataset_dir}/{dest}/images/{img_name}.jpg\")\n",
        "        runp(f\"mv {dataset_dir}/labels/{img_name}.txt {dataset_dir}/{dest}/labels/{img_name}.txt\")\n",
        "\n",
        "    for img in train_txt:\n",
        "        mv(img, True)\n",
        "    for img in val_txt:\n",
        "        mv(img, False)\n",
        "\n",
        "\n",
        "@contextlib.contextmanager\n",
        "def makedirs(name):\n",
        "    try:\n",
        "        os.makedirs(name)\n",
        "    except:\n",
        "        pass\n",
        "    yield None\n",
        "\n",
        "@contextlib.contextmanager\n",
        "def directory(name):\n",
        "    ret = os.getcwd()\n",
        "    os.chdir(name)\n",
        "    yield None\n",
        "    os.chdir(ret)\n",
        "\n",
        "def makedirs(name):\n",
        "    try:\n",
        "        os.makedirs(name)\n",
        "    except:\n",
        "        pass\n",
        "    yield None\n",
        "\n",
        "def seed(seed):\n",
        "    # torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "def launch_env(map):\n",
        "    import gym_duckietown\n",
        "    from gym_duckietown.envs import DuckietownEnv\n",
        "    env = DuckietownEnv(\n",
        "        map_name=map,\n",
        "        domain_rand=False,\n",
        "        max_steps=math.inf,\n",
        "    )\n",
        "    return env\n",
        "\n",
        "import cv2\n",
        "\n",
        "def _mod_mask(mask):\n",
        "    temp = mask.copy()\n",
        "    temp[temp == 1] = 50\n",
        "    temp[temp == 2] = 100\n",
        "    temp[temp == 3] = 150\n",
        "    temp[temp == 4] = 200\n",
        "    temp = temp.astype(\"uint8\")\n",
        "    mask = cv2.applyColorMap(temp, cv2.COLORMAP_RAINBOW)\n",
        "    return mask\n",
        "\n",
        "def display_img_seg_mask(real_img, seg_img):\n",
        "    all = np.concatenate(\n",
        "        (cv2.cvtColor(real_img, cv2.COLOR_RGB2BGR), seg_img),\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    cv2.imshow(\"image\", all)\n",
        "    cv2.waitKey(0)\n",
        "\n",
        "def prun(input, exception_on_failure=False):\n",
        "  x = run(input, exception_on_failure)\n",
        "  print(x)\n",
        "  return x"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_DIR=\"/dt_dataset\"\n",
        "IMAGE_SIZE = 416\n",
        "# this is the percentage of data that will go into the training set (as opposed to the testing set)\n",
        "SPLIT_PERCENTAGE = 0.8"
      ],
      "metadata": {
        "id": "H5nzE_-8faaO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## download dataset"
      ],
      "metadata": {
        "id": "wZ3WyoSGgroM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download data:\n",
        "runp(f\"rm -rf {DATASET_DIR}\")\n",
        "runp(f\"mkdir {DATASET_DIR}\")\n",
        "runp(f\"mkdir {DATASET_DIR}/images\")\n",
        "runp(f\"mkdir {DATASET_DIR}/labels\")\n",
        "runp(f\"mkdir {DATASET_DIR}/train\")\n",
        "runp(f\"mkdir {DATASET_DIR}/val\")\n",
        "runp(f\"mkdir {DATASET_DIR}/train/images\")\n",
        "runp(f\"mkdir {DATASET_DIR}/train/labels\")\n",
        "runp(f\"mkdir {DATASET_DIR}/val/images\")\n",
        "runp(f\"mkdir {DATASET_DIR}/val/labels\")\n",
        "!wget -O duckietown_object_detection_dataset.zip https://www.dropbox.com/s/bpd535fzmj1pz5w/duckietown%20object%20detection%20dataset-20201129T162330Z-001.zip?dl=0\n",
        "runp(f\"unzip -q duckietown_object_detection_dataset.zip -d {DATASET_DIR}\")\n",
        "runp(f\"mv {DATASET_DIR}/duckietown\\ object\\ detection\\ dataset/* {DATASET_DIR} && rm -rf {DATASET_DIR}/duckietown\\ object\\ detection\\ dataset\")\n",
        "runp(f\"rm duckietown_object_detection_dataset.zip\")"
      ],
      "metadata": {
        "id": "7fMxPPOzfUct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resize the images"
      ],
      "metadata": {
        "id": "vnDDq5Uggaet"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "with open(f\"{DATASET_DIR}/annotation/final_anns.json\") as anns:\n",
        "    annotations = json.load(anns)"
      ],
      "metadata": {
        "id": "3DiMVBsVgYye"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "npz_index = 0\n",
        "\n",
        "all_image_names = []\n",
        "    \n",
        "def save_img(img, boxes, classes):\n",
        "    global npz_index\n",
        "    cv2.imwrite(f\"{DATASET_DIR}/images/real_{npz_index}.jpg\", img)\n",
        "    with open(f\"{DATASET_DIR}/labels/real_{npz_index}.txt\", \"w\") as f:\n",
        "        for i in range(len(boxes)):\n",
        "            f.write(f\"{classes[i]} \"+\" \".join(map(str,boxes[i]))+\"\\n\")\n",
        "    npz_index += 1\n",
        "    all_image_names.append(f\"real_{npz_index}\")\n",
        "\n",
        "filenames = tqdm(os.listdir(f\"{DATASET_DIR}/frames\"))\n",
        "for filename in filenames:\n",
        "    img = cv2.imread(f\"{DATASET_DIR}/frames/{filename}\")\n",
        "\n",
        "    orig_y, orig_x = img.shape[0], img.shape[1]\n",
        "    scale_y, scale_x = IMAGE_SIZE/orig_y, IMAGE_SIZE/orig_x\n",
        "\n",
        "    img = cv2.resize(img, (IMAGE_SIZE,IMAGE_SIZE))\n",
        "\n",
        "    boxes = []\n",
        "    classes = []\n",
        "\n",
        "    if filename not in annotations:\n",
        "        continue\n",
        "\n",
        "    for detection in annotations[filename]:\n",
        "        box = detection[\"bbox\"]\n",
        "        label = detection[\"cat_name\"]\n",
        "\n",
        "        if label not in [\"duckie\", \"cone\"]:\n",
        "            continue\n",
        "\n",
        "        orig_x_min, orig_y_min, orig_w, orig_h = box\n",
        "\n",
        "        x_min = int(np.round(orig_x_min * scale_x))\n",
        "        y_min = int(np.round(orig_y_min * scale_y))\n",
        "        x_max = x_min + int(np.round(orig_w * scale_x))\n",
        "        y_max = y_min + int(np.round(orig_h * scale_y))\n",
        "\n",
        "        boxes.append([x_min, y_min, x_max, y_max])\n",
        "        classes.append(1 if label == \"duckie\" else 2)\n",
        "\n",
        "    if len(boxes) == 0:\n",
        "        continue\n",
        "\n",
        "    boxes = np.array([xminyminxmaxymax2xywfnormalized(box, IMAGE_SIZE) for box in boxes])\n",
        "    classes = np.array(classes)-1\n",
        "    \n",
        "    save_img(img, boxes, classes)\n",
        "\n",
        "train_test_split(all_image_names, SPLIT_PERCENTAGE, DATASET_DIR)"
      ],
      "metadata": {
        "id": "0Ui4hBWVgdvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6gJLjcipgNw"
      },
      "source": [
        "Mounts your google drive to move the data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQljQye7hdYp",
        "outputId": "dfbcf3b0-c7e1-47a3-e823-85c09fd7cb2f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "runp(f\"mv {DATASET_DIR} /content/drive/MyDrive/dt_dataset\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQQVO21mhkls",
        "outputId": "36660e75-c74c-44ae-b11a-f52369af4ff7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv /dt_dataset /content/drive/MyDrive/dt_dataset\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract dataset from drive"
      ],
      "metadata": {
        "id": "VpivqKqvi7PA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeEvnIDejCH3",
        "outputId": "079c3027-8048-41b5-91a8-a72dd34aaf60"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "runp(f\"cp -r /content/drive/MyDrive/dt_dataset /content{DATASET_DIR} \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKVKA9pqjDfG",
        "outputId": "02232e6b-5d36-47f2-f497-3c7ed0073cda"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp -r /content/drive/MyDrive/dt_dataset /content/dt_dataset \n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lu1Y8D2jINNm"
      },
      "source": [
        "os.chdir(f'/content{DATASET_DIR}')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0GPE6WDIV0X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca1d4b09-3127-499c-8260-706933a5279e"
      },
      "source": [
        "if not os.path.exists(\"SENTINEL\"):\n",
        "  prun(\"mkdir duckietown_dataset\")\n",
        "  prun(\"mv train duckietown_dataset && mv val duckietown_dataset\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc4VMcwmpr84"
      },
      "source": [
        "## Clone Yolov5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8L68QAeZF9G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0462b0c-e604-4ba5-eaa8-7014befb0ed5"
      },
      "source": [
        "!git clone https://github.com/guthi1/yolov5.git -b dt-obj-det\n",
        "!cd yolov5 && pip3 install -r requirements.txt\n",
        "!pip3 install torch==1.11 torchvision==0.12.0\n",
        "if not os.path.exists(\"SENTINEL\"):\n",
        "  run(\"mv duckietown_dataset yolov5\")\n",
        "!touch SENTINEL"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 6166, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 6166 (delta 0), reused 0 (delta 0), pack-reused 6162\u001b[K\n",
            "Receiving objects: 100% (6166/6166), 8.48 MiB | 13.39 MiB/s, done.\n",
            "Resolving deltas: 100% (4207/4207), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 4)) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 5)) (1.21.6)\n",
            "Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 6)) (4.6.0.66)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 7)) (7.1.2)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 8)) (6.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 9)) (1.7.3)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 10)) (1.13.0+cu116)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 11)) (0.14.0+cu116)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 12)) (4.64.1)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 15)) (2.9.1)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 19)) (0.11.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 20)) (1.3.5)\n",
            "Collecting thop\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pycocotools>=2.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 29)) (2.0.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.0->-r requirements.txt (line 10)) (4.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision>=0.8.1->-r requirements.txt (line 11)) (2.23.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.4.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.38.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (2.15.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.19.6)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.51.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.4.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->-r requirements.txt (line 20)) (2022.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (5.2.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 15)) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.8.1->-r requirements.txt (line 11)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.8.1->-r requirements.txt (line 11)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.8.1->-r requirements.txt (line 11)) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.8.1->-r requirements.txt (line 11)) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.2.2)\n",
            "Installing collected packages: thop\n",
            "Successfully installed thop-0.1.1.post2209072238\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch==1.11\n",
            "  Downloading torch-1.11.0-cp38-cp38-manylinux1_x86_64.whl (750.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 750.6 MB 18 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.12.0\n",
            "  Downloading torchvision-0.12.0-cp38-cp38-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.0 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.11) (4.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision==0.12.0) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision==0.12.0) (1.21.6)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision==0.12.0) (7.1.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.12.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.12.0) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.12.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.12.0) (2.10)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.0+cu116\n",
            "    Uninstalling torch-1.13.0+cu116:\n",
            "      Successfully uninstalled torch-1.13.0+cu116\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.14.0+cu116\n",
            "    Uninstalling torchvision-0.14.0+cu116:\n",
            "      Successfully uninstalled torchvision-0.14.0+cu116\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.14.0 requires torch==1.13.0, but you have torch 1.11.0 which is incompatible.\n",
            "torchaudio 0.13.0+cu116 requires torch==1.13.0, but you have torch 1.11.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.11.0 torchvision-0.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CalmQI9Ypx5v"
      },
      "source": [
        "# Training "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logger"
      ],
      "metadata": {
        "id": "hrOG7Ia-rrzU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a loggin system with wandb"
      ],
      "metadata": {
        "id": "FgG4Rbh7obIO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q wandb \n",
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLlmSIM2oEd8",
        "outputId": "319b5d67-ace4-4d29-b226-a9dfcce2eadd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mguthi1\u001b[0m (\u001b[33mxabjuwplb\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "ujiwX2FOrt59"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kss7Oid6OkAv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4300f993-7d99-4d91-a31a-7fbec95d9886"
      },
      "source": [
        "!mv yolov5/best.pt yolov5/best_old.pt\n",
        "!cd yolov5 && pip3 install -r requirements.txt && python3 train.py --img 416 --batch 16 --epochs 30 --data duckietown.yaml --weights yolov5s.pt\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "all_exps = os.listdir(\"yolov5/runs/train\")\n",
        "all_exps_filtered = map(lambda x: int(x.replace(\"exp\", \"1\")), filter(lambda x: x.startswith(\"exp\"), all_exps))\n",
        "all_exps_filtered = np.array(list(all_exps))\n",
        "latest_exp_index = np.argmax(all_exps)\n",
        "latest_exp = all_exps[latest_exp_index]\n",
        "print(f\"Latest exp is {latest_exp}\")\n",
        "\n",
        "prun(f\"cp yolov5/runs/train/{latest_exp}/weights/best.pt yolov5/best.pt\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat 'yolov5/best.pt': No such file or directory\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 4)) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 5)) (1.21.6)\n",
            "Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 6)) (4.6.0.66)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 7)) (7.1.2)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 8)) (6.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 9)) (1.7.3)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 10)) (1.11.0)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 11)) (0.12.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 12)) (4.64.1)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 15)) (2.9.1)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 19)) (0.11.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 20)) (1.3.5)\n",
            "Requirement already satisfied: thop in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 28)) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: pycocotools>=2.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 29)) (2.0.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.0->-r requirements.txt (line 10)) (4.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision>=0.8.1->-r requirements.txt (line 11)) (2.23.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.38.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.4.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.3.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.0.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.51.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (2.15.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.8.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (57.4.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.19.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->-r requirements.txt (line 20)) (2022.6)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (5.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 15)) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.8.1->-r requirements.txt (line 11)) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.8.1->-r requirements.txt (line 11)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.8.1->-r requirements.txt (line 11)) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.8.1->-r requirements.txt (line 11)) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.2.2)\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/guthi1/yolov5 ✅\n",
            "YOLOv5 🚀 v5.0-69-g68abb22 torch 1.11.0+cu102 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Namespace(adam=False, artifact_alias='latest', batch_size=16, bbox_interval=-1, bucket='', cache_images=False, cfg='', data='./data/duckietown.yaml', device='', entity=None, epochs=30, evolve=False, exist_ok=False, global_rank=-1, hyp='data/hyp.scratch.yaml', image_weights=False, img_size=[416, 416], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='exp', noautoanchor=False, nosave=False, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/exp2', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=16, upload_dataset=False, weights='yolov5s.pt', workers=8, world_size=1)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mguthi1\u001b[0m (\u001b[33mxabjuwplb\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/dt_dataset/yolov5/wandb/run-20221207_223845-1q0jzaet\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mexp2\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/xabjuwplb/YOLOv5\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/xabjuwplb/YOLOv5/runs/1q0jzaet\u001b[0m\n",
            "Overriding model.yaml nc=80 with nc=4\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  1    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  1    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
            "  9                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2228.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 283 layers, 7071633 parameters, 7071633 gradients, 16.5 GFLOPS\n",
            "\n",
            "Transferred 356/362 items from yolov5s.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 62 .bias, 62 conv.weight, 59 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'duckietown_dataset/train/labels.cache' images and labels... 804 found, 0 missing, 0 empty, 0 corrupted: 100% 804/804 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'duckietown_dataset/val/labels.cache' images and labels... 202 found, 0 missing, 0 empty, 0 corrupted: 100% 202/202 [00:00<?, ?it/s]\n",
            "Plotting labels... \n",
            "Images sizes do not match. This will causes images to be display incorrectly in the UI.\n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 4.92, Best Possible Recall (BPR) = 1.0000\n",
            "Image sizes 416 train, 416 test\n",
            "Using 2 dataloader workers\n",
            "Logging results to runs/train/exp2\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      0/29    0.866G    0.1242   0.01915   0.03971    0.1831        23       416: 100% 51/51 [00:14<00:00,  3.59it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:02<00:00,  2.87it/s]\n",
            "                 all         202         607     0.00401      0.0139    0.000493     8.9e-05\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      1/29     1.42G    0.1011    0.0211   0.02138    0.1436        21       416: 100% 51/51 [00:13<00:00,  3.89it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:02<00:00,  3.49it/s]\n",
            "                 all         202         607       0.581       0.101      0.0544     0.00874\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      2/29     1.42G   0.07714   0.02349   0.01338     0.114         6       416: 100% 51/51 [00:14<00:00,  3.44it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:03<00:00,  2.10it/s]\n",
            "                 all         202         607       0.725       0.211       0.182      0.0452\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      3/29     1.42G   0.07325   0.01959   0.01043    0.1033         8       416: 100% 51/51 [00:13<00:00,  3.85it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:01<00:00,  3.88it/s]\n",
            "                 all         202         607       0.777       0.247       0.271      0.0857\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      4/29     1.42G    0.0671   0.01916  0.009078   0.09534         2       416: 100% 51/51 [00:14<00:00,  3.40it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:01<00:00,  4.25it/s]\n",
            "                 all         202         607       0.759       0.287       0.359       0.141\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      5/29     1.42G   0.06292   0.01769  0.007004   0.08762        18       416: 100% 51/51 [00:12<00:00,  4.08it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:02<00:00,  2.39it/s]\n",
            "                 all         202         607       0.753       0.537       0.644       0.237\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      6/29     1.42G   0.05987   0.01642   0.00543   0.08173        21       416: 100% 51/51 [00:18<00:00,  2.81it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:01<00:00,  4.30it/s]\n",
            "                 all         202         607       0.667       0.636       0.692       0.292\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      7/29     1.42G   0.05735   0.01563   0.00459   0.07757        29       416: 100% 51/51 [00:12<00:00,  4.23it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:01<00:00,  4.10it/s]\n",
            "                 all         202         607       0.518       0.641       0.548       0.202\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      8/29     1.42G   0.05379   0.01487  0.004054   0.07271         6       416: 100% 51/51 [00:12<00:00,  4.09it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:04<00:00,  1.56it/s]\n",
            "                 all         202         607        0.75       0.748       0.801       0.371\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      9/29     1.42G   0.05255   0.01417  0.003403   0.07012         9       416: 100% 51/51 [00:12<00:00,  4.14it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:01<00:00,  4.38it/s]\n",
            "                 all         202         607       0.503       0.651       0.527       0.147\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     10/29     1.42G   0.05693   0.01419  0.004317   0.07544        11       416: 100% 51/51 [00:11<00:00,  4.30it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:01<00:00,  3.96it/s]\n",
            "                 all         202         607       0.791       0.726       0.806       0.409\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     11/29     1.42G   0.05444   0.01392  0.003782   0.07214        20       416: 100% 51/51 [00:14<00:00,  3.44it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:02<00:00,  2.47it/s]\n",
            "                 all         202         607       0.782       0.776       0.817        0.38\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     12/29     1.42G   0.05209   0.01305  0.003443   0.06858        22       416: 100% 51/51 [00:12<00:00,  4.13it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:01<00:00,  4.28it/s]\n",
            "                 all         202         607       0.826       0.786       0.851       0.416\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     13/29     1.42G   0.05057   0.01323  0.003318   0.06712        23       416: 100% 51/51 [00:13<00:00,  3.71it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:02<00:00,  2.34it/s]\n",
            "                 all         202         607       0.757       0.789       0.827       0.411\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     14/29     1.42G   0.04626   0.01297  0.003091   0.06233         9       416: 100% 51/51 [00:11<00:00,  4.32it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:02<00:00,  2.51it/s]\n",
            "                 all         202         607       0.796       0.833       0.886       0.468\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     15/29     1.42G   0.04565   0.01332  0.002742   0.06172        20       416: 100% 51/51 [00:12<00:00,  4.02it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:01<00:00,  4.32it/s]\n",
            "                 all         202         607       0.749       0.759       0.801        0.37\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     16/29     1.42G   0.04681   0.01241   0.00278     0.062        15       416: 100% 51/51 [00:15<00:00,  3.21it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:02<00:00,  2.39it/s]\n",
            "                 all         202         607       0.673       0.794        0.74       0.287\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     17/29     1.42G   0.04455   0.01215  0.002886   0.05959         9       416: 100% 51/51 [00:11<00:00,  4.33it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:02<00:00,  2.44it/s]\n",
            "                 all         202         607       0.892        0.79       0.908       0.465\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     18/29     1.42G   0.04374   0.01307    0.0025   0.05931        30       416: 100% 51/51 [00:15<00:00,  3.20it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:01<00:00,  3.90it/s]\n",
            "                 all         202         607       0.917       0.878       0.932       0.527\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     19/29     1.42G   0.03996   0.01238  0.002627   0.05496        13       416: 100% 51/51 [00:11<00:00,  4.41it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:01<00:00,  4.30it/s]\n",
            "                 all         202         607       0.921       0.845       0.927       0.521\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     20/29     1.42G   0.04193   0.01236  0.002386   0.05668        10       416: 100% 51/51 [00:12<00:00,  4.23it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:03<00:00,  1.90it/s]\n",
            "                 all         202         607       0.881       0.888       0.926       0.496\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     21/29     1.42G   0.03691   0.01189  0.002201     0.051        14       416: 100% 51/51 [00:12<00:00,  3.96it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:01<00:00,  4.63it/s]\n",
            "                 all         202         607       0.838       0.897       0.919       0.501\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     22/29     1.42G   0.03635   0.01114  0.001869   0.04936        10       416: 100% 51/51 [00:11<00:00,  4.32it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:01<00:00,  4.43it/s]\n",
            "                 all         202         607       0.893       0.908       0.938       0.557\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     23/29     1.42G    0.0354    0.0113  0.001752   0.04845        18       416: 100% 51/51 [00:14<00:00,  3.44it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:02<00:00,  2.73it/s]\n",
            "                 all         202         607       0.888       0.903       0.938       0.491\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     24/29     1.42G   0.03393   0.01135  0.001698   0.04697         9       416: 100% 51/51 [00:12<00:00,  4.14it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:01<00:00,  4.39it/s]\n",
            "                 all         202         607       0.934       0.892       0.946       0.565\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     25/29     1.42G   0.03103   0.01132  0.001508   0.04386        34       416: 100% 51/51 [00:12<00:00,  4.17it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:02<00:00,  2.62it/s]\n",
            "                 all         202         607       0.916       0.901       0.949       0.566\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     26/29     1.42G   0.03181   0.01124  0.001374   0.04443         7       416: 100% 51/51 [00:13<00:00,  3.88it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:02<00:00,  2.69it/s]\n",
            "                 all         202         607       0.927         0.9       0.949       0.584\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     27/29     1.42G   0.03027   0.01059  0.001303   0.04217        23       416: 100% 51/51 [00:12<00:00,  4.10it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:02<00:00,  3.12it/s]\n",
            "                 all         202         607       0.893       0.922       0.945       0.584\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     28/29     1.42G   0.02882   0.01041  0.001169    0.0404        14       416: 100% 51/51 [00:16<00:00,  3.00it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:01<00:00,  4.29it/s]\n",
            "                 all         202         607       0.886       0.928       0.951        0.59\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     29/29     1.42G   0.02996   0.01014  0.001154   0.04126        10       416: 100% 51/51 [00:11<00:00,  4.31it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 7/7 [00:05<00:00,  1.39it/s]\n",
            "                 all         202         607       0.913        0.91       0.951       0.609\n",
            "              duckie         202         504       0.878       0.889       0.928       0.606\n",
            "                cone         202         103       0.948       0.932       0.974       0.612\n",
            "30 epochs completed in 0.142 hours.\n",
            "\n",
            "Optimizer stripped from runs/train/exp2/weights/last.pt, 14.4MB\n",
            "Optimizer stripped from runs/train/exp2/weights/best.pt, 14.4MB\n",
            "Images sizes do not match. This will causes images to be display incorrectly in the UI.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▂▃▄▆▆▅▇▅▇▇▇▇█▇▆█████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▂▂▃▄▄▃▅▃▆▅▆▆▆▅▄▆▇▇▇▇▇▇▇█████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▅▆▇▇▇▆▅▇▅▇▇▇▇▇▇▆████▇████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▂▃▃▃▅▆▆▇▆▆▇▇▇▇▇▇▇█▇██████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▆▅▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▅▃▃▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▆▇█▆▆▅▄▄▃▃▃▃▃▃▂▃▂▂▃▂▂▂▂▂▂▂▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss █▆▅▄▃▃▃▃▂▄▃▃▃▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss █▅▄▄▃▂▂▂▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▇█▇▆▆▅▄▄▃▃▃▃▂▂▂▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▂▃▃▄▅▅▆▇▇▇████████▇▇▇▆▅▅▅▄▄▄▄\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▂▃▃▄▅▅▆▇▇▇████████▇▇▇▆▅▅▅▄▄▄▄\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ██▇▇▇▆▆▆▅▅▄▄▄▃▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.95106\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.60881\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.91321\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.91046\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.02996\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.00115\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.01014\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.02842\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.00156\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.00853\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00209\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00209\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00209\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mexp2\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/xabjuwplb/YOLOv5/runs/1q0jzaet\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 337 media file(s), 1 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20221207_223845-1q0jzaet/logs\u001b[0m\n",
            "Latest exp is exp2\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results the model"
      ],
      "metadata": {
        "id": "XKqbPm4CxY8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import torch\n",
        "\n",
        "def select_device(device='', batch_size=None):\n",
        "    import torch\n",
        "    # device = 'cpu' or '0' or '0,1,2,3'\n",
        "    cpu = device.lower() == 'cpu'\n",
        "    if cpu:\n",
        "        os.environ['CUDA_VISIBLE_DEVICES'] = '-1'  # force torch.cuda.is_available() = False\n",
        "    elif device:  # non-cpu device requested\n",
        "        os.environ['CUDA_VISIBLE_DEVICES'] = device  # set environment variable\n",
        "        assert torch.cuda.is_available(), f'CUDA unavailable, invalid device {device} requested'  # check availability\n",
        "\n",
        "    cuda = not cpu and torch.cuda.is_available()\n",
        "\n",
        "    return torch.device('cuda:0' if cuda else 'cpu')"
      ],
      "metadata": {
        "id": "LWoDN2_ZzKG-"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = torch.load(\"./yolov5/best.pt\", map_location=select_device(\"cpu\"))['model'].float()  # load to FP32\n",
        "# img = 'https://ultralytics.com/images/zidane.jpg'  # or file, Path, PIL, OpenCV, numpy, list\n",
        "# # Inference\n",
        "# results = model(img)\n",
        "\n",
        "# # Results\n",
        "# results.print()  # or .show(), .save(), .crop(), .pandas(), etc.\n"
      ],
      "metadata": {
        "id": "5K-DbbNkzFLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gz2PZ7d0qPt0"
      },
      "source": [
        "## Upload model to Duckietown's cloud"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bNXEgAFpRIH"
      },
      "source": [
        "!pip3 install git+https://github.com/duckietown/lib-dt-mooc-2021"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3HWb4wMpZc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "37bf94a2-3239-467f-b7ce-193757ca5e78"
      },
      "source": [
        "from dt_mooc.cloud import Storage\n",
        "import sys\n",
        "import torch\n",
        "\n",
        "def select_device(device='', batch_size=None):\n",
        "    import torch\n",
        "    # device = 'cpu' or '0' or '0,1,2,3'\n",
        "    cpu = device.lower() == 'cpu'\n",
        "    if cpu:\n",
        "        os.environ['CUDA_VISIBLE_DEVICES'] = '-1'  # force torch.cuda.is_available() = False\n",
        "    elif device:  # non-cpu device requested\n",
        "        os.environ['CUDA_VISIBLE_DEVICES'] = device  # set environment variable\n",
        "        assert torch.cuda.is_available(), f'CUDA unavailable, invalid device {device} requested'  # check availability\n",
        "\n",
        "    cuda = not cpu and torch.cuda.is_available()\n",
        "\n",
        "    return torch.device('cuda:0' if cuda else 'cpu')\n",
        "\n",
        "sys.path.insert(0, './yolov5')\n",
        "model = torch.load(\"./yolov5/best.pt\", map_location=select_device(\"cpu\"))['model'].float()  # load to FP32\n",
        "model.to(select_device(\"cpu\")).eval()\n",
        "\n",
        "storage = Storage(\"dt1-3nT8KSoxVh4Migd7N6Nsjy5q8BHtzjcsyz57x9FyJbx5UhJ-43dzqWFnWd8KBa1yev1g3UKnzVxZkkTbfex5eXnmoSTSmB3YdtDmc5tQuXNDk3cQ74\")\n",
        "\n",
        "storage.upload_yolov5(\"yolov5\", model, \"./yolov5/best.pt\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading file `best.pt`...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <progress\n",
              "                value='100'\n",
              "                max='100',\n",
              "                style='width: 100%'\n",
              "            >\n",
              "                100\n",
              "            </progress>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "File `best.pt` successfully uploaded! It will now be found at `courses/mooc/2021/data/nn_models/yolov5.pt`.\n",
            "Uploading file `best.pt.wts`...\n",
            "\n",
            "File `best.pt.wts` successfully uploaded! It will now be found at `courses/mooc/2021/data/nn_models/yolov5.wts`.\n",
            "Uploading file `best.pt.wts.sha256`...\n",
            "\n",
            "File `best.pt.wts.sha256` successfully uploaded! It will now be found at `courses/mooc/2021/data/nn_models/yolov5.sha256`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUVJ5BfBGq7F"
      },
      "source": [
        "# Done!"
      ]
    }
  ]
}